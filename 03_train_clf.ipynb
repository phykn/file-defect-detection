{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b3c0b8b-3c46-4c9c-9ad8-c8f208c3e36b",
   "metadata": {},
   "source": [
    "### Python import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56efeb43-45e0-4491-bcca-e7ea556e5277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import albumentations as A\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from adabelief_pytorch import AdaBelief\n",
    "\n",
    "from module.config import config_from_yaml\n",
    "from module.helper import print_time, AverageMeter\n",
    "from module.dataset import CLF_Dataset\n",
    "from module.model import CLF_MODEL\n",
    "from module.scheduler import CosineAnnealingWarmupRestarts\n",
    "\n",
    "CFG = config_from_yaml('config.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f43a31b-6ce4-4202-8136-2dff7cb920be",
   "metadata": {},
   "source": [
    "### Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77393507-b4e6-4a9a-a518-ef2ba376aba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "    A.Resize(CFG.TRAIN.IMG_SIZE, CFG.TRAIN.IMG_SIZE, p=1),\n",
    "    A.ImageCompression(quality_lower=99, quality_upper=100, p=0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.8),\n",
    "    A.ShiftScaleRotate(shift_limit=0, scale_limit=[-0.5, 0.0], rotate_limit=0, interpolation=0, border_mode=0, p=1.0),\n",
    "])\n",
    "\n",
    "valid_transform = A.Compose([\n",
    "    A.Resize(CFG.TRAIN.IMG_SIZE, CFG.TRAIN.IMG_SIZE, p=1),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fa5a8c-41a7-476c-9b59-a0c948de0b06",
   "metadata": {},
   "source": [
    "### Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef16e9b-206f-45bf-89db-eec3f11ca476",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sampler(dataset):\n",
    "    count   = np.bincount(dataset.labels).tolist()\n",
    "    weights = 1./torch.tensor(count, dtype=torch.float)\n",
    "    weights = weights[dataset.labels]\n",
    "    sampler = WeightedRandomSampler(weights=weights, num_samples=len(weights))\n",
    "    return sampler\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8457bd48-bd6a-4332-86be-f6d5466118f2",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80210be1-84da-454c-811f-ec5730741deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Data\n",
    "np.random.seed(CFG.BASE.SEED)\n",
    "\n",
    "df        = pd.read_csv(CFG.DATA.TRAIN_DATA_PATH)\n",
    "df_tmp    = df[['img_name', 'defect']].drop_duplicates()\n",
    "img_names = df_tmp['img_name'].values\n",
    "defects   = df_tmp['defect'].values\n",
    "\n",
    "train_img_names = img_names\n",
    "train_defects   = defects\n",
    "\n",
    "valid_index = np.sort(np.random.choice(range(len(train_img_names)), size=4000, replace=False))\n",
    "valid_img_names = img_names[valid_index]\n",
    "valid_defects = defects[valid_index]\n",
    "\n",
    "train_dataset    = CLF_Dataset(train_img_names, train_defects, transforms=train_transform)\n",
    "valid_dataset    = CLF_Dataset(valid_img_names, valid_defects, transforms=valid_transform)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, \n",
    "                              batch_size  = CFG.TRAIN.BATCH_SIZE, \n",
    "                              shuffle     = False,  \n",
    "                              num_workers = CFG.TRAIN.WORKERS,\n",
    "                              pin_memory  = CFG.TRAIN.PIN_MEMORY,\n",
    "                              sampler     = make_sampler(train_dataset),\n",
    "                              collate_fn  = collate_fn\n",
    "                             )\n",
    "valid_dataloader = DataLoader(valid_dataset, \n",
    "                              batch_size  = CFG.TRAIN.BATCH_SIZE, \n",
    "                              shuffle     = False, \n",
    "                              num_workers = CFG.TRAIN.WORKERS, \n",
    "                              pin_memory  = CFG.TRAIN.PIN_MEMORY,\n",
    "                              collate_fn  = collate_fn)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309f5af7-2021-496e-b0ad-5eb28b31c202",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8d87e1-50c3-49c7-9c0a-7cd850c84da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CLF_MODEL(name        = CFG.TRAIN.CLF.NAME,\n",
    "                  num_channel = CFG.DATA.N_CHANNEL, \n",
    "                  num_class   = CFG.DATA.N_CLASS,\n",
    "                  image_mean  = CFG.DATA.N_CHANNEL * [CFG.TRAIN.IMG_MEAN],\n",
    "                  image_std   = CFG.DATA.N_CHANNEL * [CFG.TRAIN.IMG_STD],\n",
    "                  smoothing   = CFG.TRAIN.CLF.SMOOTHING,\n",
    "                  pretrained  = CFG.TRAIN.CLF.PRETRAINED)\n",
    "# model.load_state_dict(torch.load('clf_model/clf012_0.9836.pth', map_location=CFG.TRAIN.DEVICE))\n",
    "model.to(CFG.TRAIN.DEVICE)\n",
    "\n",
    "optimizer = AdaBelief(model.parameters(), \n",
    "                      lr               = CFG.OPTIMIZER.CLF.LR,\n",
    "                      eps              = CFG.OPTIMIZER.CLF.EPSILON,\n",
    "                      weight_decay     = CFG.OPTIMIZER.CLF.WEIGHT_DECAY,\n",
    "                      weight_decouple  = CFG.OPTIMIZER.CLF.WEIGHT_DECOUPLE,\n",
    "                      rectify          = CFG.OPTIMIZER.CLF.RECTIFY,\n",
    "                      print_change_log = False)\n",
    "\n",
    "scheduler = CosineAnnealingWarmupRestarts(optimizer, \n",
    "                                          first_cycle_steps = CFG.SCHEDULER.CLF.FIRST_CYCLE_STEPS,\n",
    "                                          warmup_steps      = CFG.SCHEDULER.CLF.WARMUP_STEPS,\n",
    "                                          max_lr            = CFG.OPTIMIZER.CLF.LR,\n",
    "                                          min_lr            = CFG.SCHEDULER.CLF.MIN_LR)\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56f974f-e8d0-4aef-8202-9ef8ec12f323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch, dataloader, model, optimizer, scheduler, device):    \n",
    "    model.train()    \n",
    "    loss_meter = AverageMeter()\n",
    "    acc_meter  = AverageMeter()\n",
    "    pbar = tqdm(dataloader, desc=f'Epoch [{epoch}]', leave=True)\n",
    "    for images, targets in pbar:  \n",
    "        optimizer.zero_grad()        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step(epoch+loss_meter.count/len(dataloader))\n",
    "\n",
    "        images    = [image.to(device) for image in images]\n",
    "        targets   = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        with torch.cuda.amp.autocast():\n",
    "            loss_dict = model(images, targets)\n",
    "            loss      = loss_dict['loss']\n",
    "            acc       = loss_dict['acc']\n",
    "            loss_meter.update(loss.item(), n=1)\n",
    "            acc_meter.update(acc.item(), n=1)\n",
    "            \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()        \n",
    "\n",
    "        pbar.set_postfix({'Lr': optimizer.param_groups[0]['lr'], 'Loss': loss_meter.avg, 'Acc': acc_meter.avg})\n",
    " \n",
    "@torch.no_grad()\n",
    "def valid_one_epoch(dataloader, model, device, epoch=0):\n",
    "    model.eval()        \n",
    "    loss_meter = AverageMeter()\n",
    "    acc_meter  = AverageMeter()    \n",
    "    for images, targets in dataloader:\n",
    "        images    = [image.to(device) for image in images]\n",
    "        targets   = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        loss_dict = model(images, targets)\n",
    "        loss      = loss_dict['loss']\n",
    "        acc       = loss_dict['acc']        \n",
    "        loss_meter.update(loss.item(), n=1)\n",
    "        acc_meter.update(acc.item(), n=1)\n",
    "        \n",
    "    message = f'Epoch: {epoch}, Loss: {loss_meter.avg:.4f}, ACC: {acc_meter.avg:.4f}'\n",
    "    print_time(message=message, new_line=False)\n",
    "    return acc_meter.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcc6be2-f5a9-4cf1-9186-bcec66d05825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Log File\n",
    "log_name = str(datetime.now())[:19]\n",
    "log_name = log_name.replace(' ', '-').replace(':', '-')\n",
    "log_name = 'CLF_' + log_name + '.txt'\n",
    "sys.stdout = open(log_name, 'w')\n",
    "\n",
    "print_time(message='START: CLF', new_line=False)\n",
    "print(CFG)\n",
    "\n",
    "# Make Dir\n",
    "os.makedirs(CFG.MODEL.CLF_FOLDER, exist_ok=True)\n",
    "best_score = 0\n",
    "\n",
    "# Loop\n",
    "for epoch in range(0, CFG.TRAIN.CLF.EPOCHS):\n",
    "    train_one_epoch(epoch, train_dataloader, model, optimizer, scheduler, CFG.TRAIN.DEVICE)\n",
    "    score = valid_one_epoch(valid_dataloader, model, CFG.TRAIN.DEVICE, epoch=epoch)\n",
    "    \n",
    "    # Last File Save\n",
    "    model_path = os.path.join(CFG.MODEL.CLF_FOLDER, f'clf{epoch:03d}_{score:.4f}.pth')    \n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    \n",
    "    # Best File Save\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        model_path = os.path.join(CFG.MODEL.CLF_FOLDER, 'best.pth')    \n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        \n",
    "print_time(message='END: CLF')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
